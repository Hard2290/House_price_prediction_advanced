{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9782d404",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:52.361884Z",
     "iopub.status.busy": "2025-02-10T17:27:52.361470Z",
     "iopub.status.idle": "2025-02-10T17:27:56.753660Z",
     "shell.execute_reply": "2025-02-10T17:27:56.752279Z"
    },
    "papermill": {
     "duration": 4.403541,
     "end_time": "2025-02-10T17:27:56.755616",
     "exception": false,
     "start_time": "2025-02-10T17:27:52.352075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-4d38727e9718>:22: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use(\"seaborn-whitegrid\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "from category_encoders import MEstimateEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26d630b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.770283Z",
     "iopub.status.busy": "2025-02-10T17:27:56.769713Z",
     "iopub.status.idle": "2025-02-10T17:27:56.776078Z",
     "shell.execute_reply": "2025-02-10T17:27:56.774905Z"
    },
    "papermill": {
     "duration": 0.015532,
     "end_time": "2025-02-10T17:27:56.777858",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.762326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read Data\n",
    "def load_data():\n",
    "    data_directory = Path(\"/kaggle/input/house-prices-advanced-regression-techniques/\")\n",
    "    df_train = pd.read_csv(data_directory / \"train.csv\", index_col = \"Id\")\n",
    "    df_test = pd.read_csv(data_directory / \"test.csv\", index_col = \"Id\")\n",
    "\n",
    "    #Merging data for preprocessing\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    #Preprocessing\n",
    "    df = clean(df)\n",
    "    df = encode(df)\n",
    "    #Reform splits\n",
    "    df_train = df.loc[df_train.index, :]\n",
    "    df_test = df.loc[df_test.index, :]\n",
    "\n",
    "    #dropping NA in target column\n",
    "    df_train.dropna(subset=[\"SalePrice\"], inplace=True)\n",
    "\n",
    "    #X_train, X_valid = train_test_split(df_train, test_size=0.3, random_state=6)\n",
    "    #X_train, X_valid, df_test = impute(X_train, X_valid, df_test)\n",
    "    #X = pd.concat([X_train, X_valid])\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a4081f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.791531Z",
     "iopub.status.busy": "2025-02-10T17:27:56.791185Z",
     "iopub.status.idle": "2025-02-10T17:27:56.797162Z",
     "shell.execute_reply": "2025-02-10T17:27:56.796096Z"
    },
    "papermill": {
     "duration": 0.014799,
     "end_time": "2025-02-10T17:27:56.798931",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.784132",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df[\"Exterior2nd\"] = df[\"Exterior2nd\"].replace({\"Brk Cmn\":\"BrkComm\", \"Wd Shng\":\"WdShing\", \"CmentBd\":\"CemntBd\"})\n",
    "    df[\"MSZoning\"] = df[\"MSZoning\"].replace({\"C (all)\":\"C\"})\n",
    "    df[\"Neighborhood\"] = df[\"Neighborhood\"].replace({\"NAmes\":\"Names\"})\n",
    "    df[\"BldgType\"] = df[\"BldgType\"].replace({\"2fmCon\":\"2FmCon\", \"Duplex\":\"Duplx\", \"Twnhs\":\"TwnhsI\"})\n",
    "\n",
    "    df[\"GarageYrBlt\"] = df[\"GarageYrBlt\"].where(df.GarageYrBlt <= 2010, df.YearBuilt)\n",
    "\n",
    "    df.rename(columns = {\n",
    "        \"1stFlrSF\":\"FirstFlrSF\",\n",
    "        \"2ndFlrSF\":\"SecondFlrSF\",\n",
    "        \"3SsnPorch\":\"Threeseasonporch\"\n",
    "    }, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "915bc1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.812655Z",
     "iopub.status.busy": "2025-02-10T17:27:56.812314Z",
     "iopub.status.idle": "2025-02-10T17:27:56.820714Z",
     "shell.execute_reply": "2025-02-10T17:27:56.819564Z"
    },
    "papermill": {
     "duration": 0.01743,
     "end_time": "2025-02-10T17:27:56.822585",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.805155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The numeric features are already encoded correctly (`float` for\n",
    "# continuous, `int` for discrete), but the categoricals we'll need to\n",
    "# do ourselves. Note in particular, that the `MSSubClass` feature is\n",
    "# read as an `int` type, but is actually a (nominative) categorical.\n",
    "\n",
    "# The nominative (unordered) categorical features\n",
    "features_nom = [\"MSSubClass\", \"MSZoning\", \"Street\", \"Alley\", \"LandContour\", \"LotConfig\", \n",
    "                \"Neighborhood\", \"Condition1\", \"Condition2\", \"BldgType\", \"HouseStyle\", \n",
    "                \"RoofStyle\", \"RoofMatl\", \"Exterior1st\", \"Exterior2nd\", \"MasVnrType\", \"Foundation\", \n",
    "                \"Heating\", \"GarageType\", \"MiscFeature\", \"SaleType\", \"SaleCondition\"]\n",
    "\n",
    "\n",
    "# The ordinal (ordered) categorical features \n",
    "\n",
    "# Pandas calls the categories \"levels\"\n",
    "five_levels = [\"Po\", \"Fa\", \"TA\", \"Gd\", \"Ex\"]\n",
    "ten_levels = list(range(10))\n",
    "\n",
    "ordered_levels = {\n",
    "    \"OverallQual\": ten_levels,\n",
    "    \"OverallCond\": ten_levels,\n",
    "    \"ExterQual\": five_levels,\n",
    "    \"ExterCond\": five_levels,\n",
    "    \"BsmtQual\": five_levels,\n",
    "    \"BsmtCond\": five_levels,\n",
    "    \"HeatingQC\": five_levels,\n",
    "    \"KitchenQual\": five_levels,\n",
    "    \"FireplaceQu\": five_levels,\n",
    "    \"GarageQual\": five_levels,\n",
    "    \"GarageCond\": five_levels,\n",
    "    \"PoolQC\": five_levels,\n",
    "    \"LotShape\": [\"Reg\", \"IR1\", \"IR2\", \"IR3\"],\n",
    "    \"LandSlope\": [\"Sev\", \"Mod\", \"Gtl\"],\n",
    "    \"BsmtExposure\": [\"No\", \"Mn\", \"Av\", \"Gd\"],\n",
    "    \"BsmtFinType1\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"BsmtFinType2\": [\"Unf\", \"LwQ\", \"Rec\", \"BLQ\", \"ALQ\", \"GLQ\"],\n",
    "    \"Functional\": [\"Sal\", \"Sev\", \"Maj1\", \"Maj2\", \"Mod\", \"Min2\", \"Min1\", \"Typ\"],\n",
    "    \"GarageFinish\": [\"Unf\", \"RFn\", \"Fin\"],\n",
    "    \"PavedDrive\": [\"N\", \"P\", \"Y\"],\n",
    "    \"Utilities\": [\"NoSeWa\", \"NoSewr\", \"AllPub\"],\n",
    "    \"CentralAir\": [\"N\", \"Y\"],\n",
    "    \"Electrical\": [\"Mix\", \"FuseP\", \"FuseF\", \"FuseA\", \"SBrkr\"],\n",
    "    \"Fence\": [\"MnWw\", \"GdWo\", \"MnPrv\", \"GdPrv\"],\n",
    "}\n",
    "\n",
    "#Add a none for missing values\n",
    "ordered_levels = {key:[\"None\"]+values for key,values in ordered_levels.items()}\n",
    "ordered_cols = [col for col,values in ordered_levels.items()]\n",
    "\n",
    "#high_cardinality_nom_cols = [\"MSSubClass\",\"Neighborhood\",\"Exterior1st\",\"Exterior2nd\"]\n",
    "#low_cardinality_nom_cols = df[features_nom].drop(high_cardinality_nom_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf87f2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.836528Z",
     "iopub.status.busy": "2025-02-10T17:27:56.836123Z",
     "iopub.status.idle": "2025-02-10T17:27:56.841821Z",
     "shell.execute_reply": "2025-02-10T17:27:56.840629Z"
    },
    "papermill": {
     "duration": 0.01453,
     "end_time": "2025-02-10T17:27:56.843527",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.828997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode(df):\n",
    "    #Nominal categories\n",
    "    for name in features_nom:\n",
    "        df[name] = df[name].astype(\"category\")\n",
    "        #Add a none for missing values\n",
    "        if \"None\" not in df[name].cat.categories:\n",
    "            df[name] = df[name].cat.add_categories(\"None\")\n",
    "\n",
    "    #Ordinal categories\n",
    "    for name,values in ordered_levels.items():\n",
    "        df[name] = df[name].astype(CategoricalDtype(values,\n",
    "                                                    ordered=True))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c7b2ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.857871Z",
     "iopub.status.busy": "2025-02-10T17:27:56.857486Z",
     "iopub.status.idle": "2025-02-10T17:27:56.865459Z",
     "shell.execute_reply": "2025-02-10T17:27:56.864525Z"
    },
    "papermill": {
     "duration": 0.016944,
     "end_time": "2025-02-10T17:27:56.867246",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.850302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def impute(X_train, X_valid, df_test):\n",
    "    df = pd.concat([X_train, X_valid, df_test])\n",
    "    cat_cols = features_nom + ordered_cols\n",
    "    numerical_cols = df.drop(cat_cols, axis=1).select_dtypes(\"number\").columns\n",
    "\n",
    "    X_train = df.loc[X_train.index,:]\n",
    "    X_valid = df.loc[X_valid.index,:]\n",
    "    df_test = df.loc[df_test.index,:]\n",
    "\n",
    "    num_imputer = SimpleImputer(strategy = \"mean\")\n",
    "    cat_imputer = SimpleImputer(strategy = \"constant\", fill_value = \"0\")\n",
    "\n",
    "    #numerical imputation\n",
    "    imputed_num_X_train = pd.DataFrame(num_imputer.fit_transform(X_train[numerical_cols]))\n",
    "    imputed_num_X_valid = pd.DataFrame(num_imputer.transform(X_valid[numerical_cols]))\n",
    "    imputed_num_df_test = pd.DataFrame(num_imputer.transform(df_test[numerical_cols]))\n",
    "\n",
    "    imputed_num_X_train.columns = X_train[numerical_cols].columns\n",
    "    imputed_num_X_valid.columns = X_valid[numerical_cols].columns\n",
    "    imputed_num_df_test.columns = df_test[numerical_cols].columns\n",
    "\n",
    "    #categorical imputation\n",
    "    imputed_cat_X_train = pd.DataFrame(cat_imputer.fit_transform(X_train[cat_cols]))\n",
    "    imputed_cat_X_valid = pd.DataFrame(cat_imputer.transform(X_valid[cat_cols]))\n",
    "    imputed_cat_df_test = pd.DataFrame(cat_imputer.transform(df_test[cat_cols]))\n",
    "\n",
    "    imputed_cat_X_train.columns = X_train[cat_cols].columns\n",
    "    imputed_cat_X_valid.columns = X_valid[cat_cols].columns\n",
    "    imputed_cat_df_test.columns = df_test[cat_cols].columns\n",
    "\n",
    "    #merging and return\n",
    "    X_train = pd.concat([imputed_num_X_train, imputed_cat_X_train], axis=1, join=\"outer\")\n",
    "    X_valid = pd.concat([imputed_num_X_valid, imputed_cat_X_valid], axis=1, join=\"outer\")\n",
    "    df_test = pd.concat([imputed_num_df_test, imputed_cat_df_test], axis=1, join=\"outer\")\n",
    "\n",
    "    return X_train, X_valid, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b664729",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:56.880921Z",
     "iopub.status.busy": "2025-02-10T17:27:56.880537Z",
     "iopub.status.idle": "2025-02-10T17:27:57.046043Z",
     "shell.execute_reply": "2025-02-10T17:27:57.044994Z"
    },
    "papermill": {
     "duration": 0.17457,
     "end_time": "2025-02-10T17:27:57.047981",
     "exception": false,
     "start_time": "2025-02-10T17:27:56.873411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train, df_test = load_data()\n",
    "X_train, X_valid = train_test_split(df_train, test_size=0.3, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfe6087c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.061631Z",
     "iopub.status.busy": "2025-02-10T17:27:57.061304Z",
     "iopub.status.idle": "2025-02-10T17:27:57.190514Z",
     "shell.execute_reply": "2025-02-10T17:27:57.189298Z"
    },
    "papermill": {
     "duration": 0.138257,
     "end_time": "2025-02-10T17:27:57.192488",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.054231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Imputation(Preprocessing)\n",
    "df = pd.concat([X_train, X_valid, df_test])\n",
    "\n",
    "cat_cols = features_nom + ordered_cols\n",
    "\n",
    "numerical_cols = df.drop(cat_cols, axis=1).select_dtypes(\"number\").columns\n",
    "\n",
    "#num_col_missing = [col for col in numerical_cols if df[col].isnull().any()]\n",
    "\n",
    "#cat_col_missing = [col for col in cat_cols if df[col].isnull().any()]\n",
    "    \n",
    "\n",
    "X_train = df.loc[X_train.index,:]\n",
    "\n",
    "X_valid = df.loc[X_valid.index,:]\n",
    "\n",
    "df_test = df.loc[df_test.index,:]\n",
    "\n",
    "\n",
    "num_imputer = SimpleImputer(strategy = \"median\")\n",
    "\n",
    "cat_imputer = SimpleImputer(strategy = \"most_frequent\")\n",
    "    \n",
    "\n",
    "#numerical imputation\n",
    "\n",
    "imputed_num_X_train = pd.DataFrame(num_imputer.fit_transform(X_train[numerical_cols]))\n",
    "\n",
    "imputed_num_X_valid = pd.DataFrame(num_imputer.transform(X_valid[numerical_cols]))\n",
    "\n",
    "imputed_num_df_test = pd.DataFrame(num_imputer.transform(df_test[numerical_cols]))\n",
    "\n",
    "\n",
    "\n",
    "imputed_num_X_train.columns = X_train[numerical_cols].columns\n",
    "\n",
    "imputed_num_X_valid.columns = X_valid[numerical_cols].columns\n",
    "\n",
    "imputed_num_df_test.columns = df_test[numerical_cols].columns\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#categorical imputation\n",
    "\n",
    "imputed_cat_X_train = pd.DataFrame(cat_imputer.fit_transform(X_train[cat_cols]))\n",
    "\n",
    "imputed_cat_X_valid = pd.DataFrame(cat_imputer.transform(X_valid[cat_cols]))\n",
    "\n",
    "imputed_cat_df_test = pd.DataFrame(cat_imputer.transform(df_test[cat_cols]))\n",
    "\n",
    "\n",
    "\n",
    "imputed_cat_X_train.columns = X_train[cat_cols].columns\n",
    "\n",
    "imputed_cat_X_valid.columns = X_valid[cat_cols].columns\n",
    "\n",
    "imputed_cat_df_test.columns = df_test[cat_cols].columns\n",
    "\n",
    "\n",
    "#merging and return\n",
    "\n",
    "X_train = pd.concat([imputed_num_X_train, imputed_cat_X_train], axis=1, join=\"outer\")\n",
    "\n",
    "X_valid = pd.concat([imputed_num_X_valid, imputed_cat_X_valid], axis=1, join=\"outer\")\n",
    "\n",
    "df_test = pd.concat([imputed_num_df_test, imputed_cat_df_test], axis=1, join=\"outer\")\n",
    "\n",
    "df_train = pd.concat([X_train, X_valid])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b0856e15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.206136Z",
     "iopub.status.busy": "2025-02-10T17:27:57.205722Z",
     "iopub.status.idle": "2025-02-10T17:27:57.211999Z",
     "shell.execute_reply": "2025-02-10T17:27:57.211154Z"
    },
    "papermill": {
     "duration": 0.014984,
     "end_time": "2025-02-10T17:27:57.213732",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.198748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.concat([X_train, X_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b68cb42d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.227118Z",
     "iopub.status.busy": "2025-02-10T17:27:57.226730Z",
     "iopub.status.idle": "2025-02-10T17:27:57.231941Z",
     "shell.execute_reply": "2025-02-10T17:27:57.230974Z"
    },
    "papermill": {
     "duration": 0.01364,
     "end_time": "2025-02-10T17:27:57.233564",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.219924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_dataset(X, y, model=XGBRegressor()):\n",
    "    #Label Encoding\n",
    "    X = X.apply(lambda x : pd.factorize(x)[0])\n",
    "\n",
    "    #we need RMSLE(Root mean Squared Log Error)\n",
    "    log_y = np.log(y)\n",
    "    score = cross_val_score(\n",
    "        model, X, log_y, cv=5, scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "    score = -1*score.mean()\n",
    "    score = np.sqrt(score)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd1ab71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.246763Z",
     "iopub.status.busy": "2025-02-10T17:27:57.246451Z",
     "iopub.status.idle": "2025-02-10T17:27:57.252822Z",
     "shell.execute_reply": "2025-02-10T17:27:57.251876Z"
    },
    "papermill": {
     "duration": 0.014698,
     "end_time": "2025-02-10T17:27:57.254446",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.239748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = df_train.copy()\\ny = X.pop(\"SalePrice\")\\n\\nBaselineScore = score_dataset(X, y)\\nprint(f\"Baseline Score: {BaselineScore:.5f} RMSLE\")\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X = df_train.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "\n",
    "BaselineScore = score_dataset(X, y)\n",
    "print(f\"Baseline Score: {BaselineScore:.5f} RMSLE\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ada0ce3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.268020Z",
     "iopub.status.busy": "2025-02-10T17:27:57.267541Z",
     "iopub.status.idle": "2025-02-10T17:27:57.276025Z",
     "shell.execute_reply": "2025-02-10T17:27:57.275034Z"
    },
    "papermill": {
     "duration": 0.017536,
     "end_time": "2025-02-10T17:27:57.278139",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.260603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y, discrete_fea=True):\n",
    "    X = X.copy()\n",
    "    #Label Encoding\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname],_ = X[colname].factorize()\n",
    "    #All discrete features should now have integer data types\n",
    "    if discrete_fea:\n",
    "        discrete_fea = X.dtypes == \"int\"\n",
    "    mi_scores = mutual_info_regression(X, y, discrete_features = discrete_fea, random_state = 6)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index = X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending = False)\n",
    "    return mi_scores\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending = True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6576f5fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.296484Z",
     "iopub.status.busy": "2025-02-10T17:27:57.295971Z",
     "iopub.status.idle": "2025-02-10T17:27:57.301773Z",
     "shell.execute_reply": "2025-02-10T17:27:57.300672Z"
    },
    "papermill": {
     "duration": 0.01625,
     "end_time": "2025-02-10T17:27:57.304421",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.288171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_uninformative(X, mi_scores):\n",
    "    return X.loc[:, mi_scores > 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f97511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.319760Z",
     "iopub.status.busy": "2025-02-10T17:27:57.319275Z",
     "iopub.status.idle": "2025-02-10T17:27:57.325151Z",
     "shell.execute_reply": "2025-02-10T17:27:57.324219Z"
    },
    "papermill": {
     "duration": 0.015466,
     "end_time": "2025-02-10T17:27:57.326813",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.311347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nX = df_train.copy()\\ny = X.pop(\"SalePrice\")\\nmi_scores = make_mi_scores(X, y)\\nX = drop_uninformative(X, mi_scores)\\n\\nscore_dataset(X, y)\\n#mi_scores.head(20)\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "X = df_train.copy()\n",
    "y = X.pop(\"SalePrice\")\n",
    "mi_scores = make_mi_scores(X, y)\n",
    "X = drop_uninformative(X, mi_scores)\n",
    "\n",
    "score_dataset(X, y)\n",
    "#mi_scores.head(20)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74da99bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.340870Z",
     "iopub.status.busy": "2025-02-10T17:27:57.340488Z",
     "iopub.status.idle": "2025-02-10T17:27:57.351332Z",
     "shell.execute_reply": "2025-02-10T17:27:57.350146Z"
    },
    "papermill": {
     "duration": 0.019942,
     "end_time": "2025-02-10T17:27:57.353161",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.333219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Feature Engineering_Creating Features\n",
    "def label_encode(df):\n",
    "    X = df.copy()\n",
    "    for colname in X.select_dtypes([\"category\", \"object\"]):\n",
    "        X[colname],_ = X[colname].factorize()\n",
    "    return X\n",
    "\n",
    "def mathematical_transforms(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"LivLotRatio\"] = df.GrLivArea / df.LotArea\n",
    "    X[\"Spaciousness\"] = (df.FirstFlrSF + df.SecondFlrSF) / df.TotRmsAbvGrd\n",
    "    return X\n",
    "\n",
    "def interactions(df):\n",
    "    X1 = pd.get_dummies(df.BldgType, prefix = \"Bldg\")\n",
    "    X1 = X1.mul(df.GrLivArea, axis = 0)\n",
    "    return X1\n",
    "\n",
    "def more_interactions(df):\n",
    "    X = df.copy()\n",
    "    X1 = pd.DataFrame()\n",
    "    X[\"OverallQual\"],_ = X[\"OverallQual\"].factorize()\n",
    "    X[\"OverallCond\"],_ = X[\"OverallCond\"].factorize()\n",
    "    X1[\"ResultCond\"] = (X.OverallQual * X.OverallCond)\n",
    "\n",
    "    X[\"BsmtQual\"],_ = X[\"BsmtQual\"].factorize()\n",
    "    X1[\"BsmtWeightage\"] = (X.BsmtQual * X.TotalBsmtSF)\n",
    "    return X1\n",
    "    \n",
    "def linearize_area(df):\n",
    "    X = pd.DataFrame()\n",
    "    area_features = [\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\n",
    "                     \"FirstFlrSF\",\"SecondFlrSF\",\"ScreenPorch\",\"PoolArea\",\"LotArea\",\"GarageArea\",\n",
    "                     \"GrLivArea\",\"MasVnrArea\",\"BsmtUnfSF\",\"TotalBsmtSF\"]\n",
    "    for colname in area_features:\n",
    "        X[colname + \"_squareroot(in ft)\"] = np.sqrt(df[colname])\n",
    "    return X\n",
    "\n",
    "def counts(df):\n",
    "    X1 = pd.DataFrame()\n",
    "    X1 = df[[\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"Threeseasonporch\", \"ScreenPorch\"]].gt(0.0).sum(axis=1)\n",
    "    return X1\n",
    "\n",
    "def break_down(df):\n",
    "    X1 = pd.DataFrame()\n",
    "    X1[\"MSClass\"] = df.MSSubClass.str.split(\"_\", n=1, expand = True)[0]\n",
    "    return X1\n",
    "\n",
    "def group_transforms(df):\n",
    "    X1 = pd.DataFrame()\n",
    "    X1[\"MedNhbdArea\"] = df.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "    X1[\"VarFromMed\"] = (df.GrLivArea - df.MedNhbdArea)\n",
    "    return X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88274e5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.367717Z",
     "iopub.status.busy": "2025-02-10T17:27:57.367324Z",
     "iopub.status.idle": "2025-02-10T17:27:57.374628Z",
     "shell.execute_reply": "2025-02-10T17:27:57.373614Z"
    },
    "papermill": {
     "duration": 0.016761,
     "end_time": "2025-02-10T17:27:57.376374",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.359613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Clustering with K-Means\n",
    "cluster_features = [\"LotArea\", \"TotalBsmtSF\", \"FirstFlrSF\", \"SecondFlrSF\", \"GrLivArea\", \"GarageArea\"]\n",
    "\n",
    "def cluster_labels(df, features, n_clusters = 20):\n",
    "    X = df.copy()\n",
    "    X_scaled = X.loc[:, features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters = n_clusters, n_init = 50, random_state = 6)\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Cluster\"] = kmeans.fit_predict(X_scaled)\n",
    "    return X_new\n",
    "\n",
    "def cluster_distance(df, features, n_clusters = 20):\n",
    "    X = df.copy()\n",
    "    X_scaled = X.loc[:, features]\n",
    "    X_scaled = (X_scaled - X_scaled.mean(axis=0)) / X_scaled.std(axis=0)\n",
    "    kmeans = KMeans(n_clusters = n_clusters, n_init = 50, random_state = 6)\n",
    "    X_cd = kmeans.fit_transform(X_scaled)\n",
    "    X_cd = pd.DataFrame(\n",
    "        X_cd, columns = [f\"Centroid_{i}\" for i in range(X_cd.shape[1])]\n",
    "    )\n",
    "    return X_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "962f4985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.390675Z",
     "iopub.status.busy": "2025-02-10T17:27:57.390285Z",
     "iopub.status.idle": "2025-02-10T17:27:57.398430Z",
     "shell.execute_reply": "2025-02-10T17:27:57.397080Z"
    },
    "papermill": {
     "duration": 0.017301,
     "end_time": "2025-02-10T17:27:57.400263",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.382962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Principal Component Analysis\n",
    "def apply_pca(X, standardize = True):\n",
    "    #Standardize\n",
    "    if standardize:\n",
    "        X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    #Create Principal Components\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    #Convert to DataFrame\n",
    "    component_names = [f\"PC{i+1}\" for i in range(X_pca.shape[1])]\n",
    "    X_pca = pd.DataFrame(X_pca, columns = component_names)\n",
    "    #Create Loadings\n",
    "    loadings = pd.DataFrame(\n",
    "        pca.components_.T, columns = component_names, index = X.columns\n",
    "    )\n",
    "    return pca, X_pca, loadings\n",
    "\n",
    "def plot_variance(pca, width = 8, dpi = 100):\n",
    "    #Create Figure\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    n = pca.n_components_\n",
    "    grid = np.arange(1, n+1)\n",
    "    #% Explained Variance\n",
    "    evr = pca.explained_variance_ratio_\n",
    "    axs[0].bar(grid, evr)\n",
    "    axs[0].set(\n",
    "        xlabel = \"Principal Components\", title = \"% Explained Variance\", ylim = (0.0, 0.15)\n",
    "    )\n",
    "    #%Cumulative Variance\n",
    "    cv = np.cumsum(evr)\n",
    "    axs[1].plot(np.r_[0, grid], np.r_[0, cv], \"o-\" )\n",
    "    axs[1].set(\n",
    "        xlabel = \"Principal Components\", title = \"% Cumulative Variance\", ylim = (0.0, 1.0)\n",
    "    )\n",
    "    #Set up figure\n",
    "    fig.set(figwidth = width, dpi = dpi)\n",
    "    return axs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52701a60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.414127Z",
     "iopub.status.busy": "2025-02-10T17:27:57.413716Z",
     "iopub.status.idle": "2025-02-10T17:27:57.417460Z",
     "shell.execute_reply": "2025-02-10T17:27:57.416434Z"
    },
    "papermill": {
     "duration": 0.012464,
     "end_time": "2025-02-10T17:27:57.419090",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.406626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X = label_encode(X)\n",
    "#X[\"Utilities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09004444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.432820Z",
     "iopub.status.busy": "2025-02-10T17:27:57.432432Z",
     "iopub.status.idle": "2025-02-10T17:27:57.437910Z",
     "shell.execute_reply": "2025-02-10T17:27:57.436854Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2025-02-10T17:27:57.439576",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.425475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_features = [\"GarageArea\", \"YearRemodAdd\", \"TotalBsmtSF\", \"GrLivArea\"] #Select only numeric features\n",
    "\n",
    "def pca_components(df, features):\n",
    "    X = df.loc[:, features]\n",
    "    _, X_pca, _ = apply_pca(X)\n",
    "    return X_pca\n",
    "\n",
    "def pca_inspired(df):\n",
    "    X = pd.DataFrame()\n",
    "    X[\"Feature 1\"] = df.GrLivArea + df.TotalBsmtSF\n",
    "    X[\"Feature 2\"] = df.YearRemodAdd * df.TotalBsmtSF\n",
    "    X[\"Feature 3\"] = df.GarageArea * df.YearRemodAdd\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "398d2b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.453386Z",
     "iopub.status.busy": "2025-02-10T17:27:57.452992Z",
     "iopub.status.idle": "2025-02-10T17:27:57.457266Z",
     "shell.execute_reply": "2025-02-10T17:27:57.456340Z"
    },
    "papermill": {
     "duration": 0.012993,
     "end_time": "2025-02-10T17:27:57.458884",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.445891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Outliers Indicator\n",
    "def indicate_outliers(df):\n",
    "    X_new = pd.DataFrame()\n",
    "    X_new[\"Outlier\"] = (df.Neighborhood == \"Edwards\") & (df.SaleCondition == \"Partial\")\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6167f3bb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.472727Z",
     "iopub.status.busy": "2025-02-10T17:27:57.472379Z",
     "iopub.status.idle": "2025-02-10T17:27:57.477061Z",
     "shell.execute_reply": "2025-02-10T17:27:57.476064Z"
    },
    "papermill": {
     "duration": 0.013427,
     "end_time": "2025-02-10T17:27:57.478714",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.465287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Correlation Matrix Plot\n",
    "def corrplot(df, method = \"pearson\", annot=True, **kwargs):\n",
    "    sns.clustermap(\n",
    "        df.corr(method, numeric_only=True),\n",
    "        vmin = 0.0,\n",
    "        vmax = 1.0,\n",
    "        cmap = \"icefire\",\n",
    "        method = \"complete\",\n",
    "        annot = annot, \n",
    "        **kwargs\n",
    "    )\n",
    "#corrplot(X, annot=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c88256df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.492413Z",
     "iopub.status.busy": "2025-02-10T17:27:57.492024Z",
     "iopub.status.idle": "2025-02-10T17:27:57.499845Z",
     "shell.execute_reply": "2025-02-10T17:27:57.498847Z"
    },
    "papermill": {
     "duration": 0.01662,
     "end_time": "2025-02-10T17:27:57.501642",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.485022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Target Encoding(strategy like cross-validation to use 100% data)\n",
    "class CrossFoldEncoder:\n",
    "    def __init__(self, encoder, **kwargs):\n",
    "        self.encoder_ = encoder\n",
    "        self.kwargs_ = kwargs\n",
    "        self.cv_ = KFold(n_splits = 5)\n",
    "        \n",
    "    def fit_transform(self, X, y, cols):\n",
    "        self.fitted_encoders_ = []\n",
    "        self.cols_ = cols\n",
    "        X_encoded = []\n",
    "        for idx_encode, idx_train in self.cv_.split(X):\n",
    "            #print(f\"Encoding indices: {idx_encode} and {idx_train}\")\n",
    "            fitted_encoder = self.encoder_(cols = cols, **self.kwargs_)\n",
    "            fitted_encoder.fit(\n",
    "                X.iloc[idx_encode, :], y.iloc[idx_encode]\n",
    "            )\n",
    "            transformed_data = fitted_encoder.transform(X.iloc[idx_train, :])[cols]\n",
    "            #print(f\"Transformed data columns: {transformed_data.columns}\")\n",
    "\n",
    "            X_encoded.append(transformed_data)\n",
    "            self.fitted_encoders_.append(fitted_encoder)\n",
    "        X_encoded = pd.concat(X_encoded)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded\n",
    "\n",
    "    #for test data - averaging out all the transformations learned through training data\n",
    "    def transform(self, X):\n",
    "        from functools import reduce\n",
    "        X_encoded_list = []\n",
    "        for fitted_encoder in self.fitted_encoders_:\n",
    "            X_encoded = fitted_encoder.transform(X)\n",
    "            X_encoded_list.append(X_encoded[self.cols_])\n",
    "        X_encoded = reduce(\n",
    "            lambda x, y: x.add(y, fill_value = 0), X_encoded_list\n",
    "        ) / len(X_encoded_list)\n",
    "        X_encoded.columns = [name + \"_encoded\" for name in X_encoded.columns]\n",
    "        return X_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b2eb9c52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.515758Z",
     "iopub.status.busy": "2025-02-10T17:27:57.515391Z",
     "iopub.status.idle": "2025-02-10T17:27:57.524565Z",
     "shell.execute_reply": "2025-02-10T17:27:57.523435Z"
    },
    "papermill": {
     "duration": 0.01789,
     "end_time": "2025-02-10T17:27:57.526182",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.508292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_features(df, df_test = None):\n",
    "    X = df.copy()\n",
    "    y = X.pop(\"SalePrice\")\n",
    "    mi_scores = make_mi_scores(X, y)\n",
    "    #print(len(X))\n",
    "    #print(len(df_test))\n",
    "    \n",
    "    #Combine test and training data\n",
    "    if df_test is not None:\n",
    "        X_test = df_test.copy()\n",
    "        X_test.pop(\"SalePrice\")\n",
    "        X = pd.concat([X_test, X])\n",
    "\n",
    "    #print(len(X))\n",
    "    #Based on MI Scores\n",
    "    X = drop_uninformative(X, mi_scores)\n",
    "\n",
    "    #Transformations\n",
    "    # 1.Mathematical Transformations\n",
    "    #X = X.join(Mathematical_transforms(X))\n",
    "    # 2.Interactions\n",
    "    #X = X.join(interactions(X))\n",
    "    \"\"\"\n",
    "    X1 = pd.get_dummies(df.BldgType, prefix = \"Bldg\")\n",
    "    X = X1.mul(X.GrLivArea, axis = 0)\n",
    "    \"\"\"\n",
    "    #X = X.join(more_interactions(X))\n",
    "    \"\"\"\n",
    "    X[\"OverallQual\"],_ = X[\"OverallQual\"].factorize()\n",
    "    X[\"OverallCond\"],_ = X[\"OverallCond\"].factorize()\n",
    "    X[\"BsmtQual\"],_ = X[\"BsmtQual\"].factorize()\n",
    "    \n",
    "    X[\"ResultCond\"] = (X.OverallQual * X.OverallCond)\n",
    "    X[\"BsmtWeightage\"] = (X.BsmtQual * X.TotalBsmtSF)\n",
    "    \"\"\"\n",
    "    # 3.Linearize Area by Taking Square Root\n",
    "    #X = X.join(linearize_area(X))\n",
    "    \n",
    "    area_features = [\"WoodDeckSF\",\"OpenPorchSF\",\"EnclosedPorch\",\n",
    "                     \"FirstFlrSF\",\"SecondFlrSF\",\"ScreenPorch\",\"PoolArea\",\"LotArea\",\"GarageArea\",\n",
    "                     \"GrLivArea\",\"MasVnrArea\",\"BsmtUnfSF\",\"TotalBsmtSF\"]\n",
    "    for colname in area_features:\n",
    "        X[colname] = X[colname].fillna(0)\n",
    "        new_column_name = colname + \"_squareroot(in ft)\"\n",
    "        X[new_column_name] = np.sqrt(X[colname].clip(lower=0))\n",
    "    \n",
    "    # 4.Counts\n",
    "    #X = X.join(counts(X))\n",
    "    X[\"Counts_\"] = X[[\"WoodDeckSF\", \"OpenPorchSF\", \"EnclosedPorch\", \"ScreenPorch\"]].gt(0.0).sum(axis=1)\n",
    "    # 5.Break Down\n",
    "    #X = X.join(break_down(X))\n",
    "    X['MSSubClass'] = X['MSSubClass'].astype(str)\n",
    "    X[\"MSClass\"] = X.MSSubClass.str.split(\"_\", n=1, expand = True)[0]\n",
    "    X['MSSubClass'] = X['MSSubClass'].astype(\"object\")\n",
    "    # 6.Group Transformations\n",
    "    #X = X.join(group_transforms(X))\n",
    "    \"\"\"\n",
    "    X[\"MedNhbdArea\"] = X.groupby(\"Neighborhood\")[\"GrLivArea\"].transform(\"median\")\n",
    "    X[\"VarFromMed\"] = (X.GrLivArea - X.MedNhbdArea)\n",
    "    \"\"\"\n",
    "    #Principal Component Analysis (PCA)\n",
    "    #X = X.join(indicate_outliers(X))\n",
    "    #X[\"Outlier\"] = (X.Neighborhood == \"Edwards\") & (X.SaleCondition == \"Partial\")\n",
    "    #X = X.join(pca_inspired(X))\n",
    "    \"\"\"\n",
    "    X[\"Feature 1\"] = X.GrLivArea + X.TotalBsmtSF\n",
    "    X[\"Feature 2\"] = X.YearRemodAdd * X.TotalBsmtSF\n",
    "    X[\"Feature 3\"] = X.GarageArea * X.YearRemodAdd\n",
    "    \"\"\"\n",
    "    #Clustering\n",
    "    #X = X.join(cluster_labels(X, cluster_features))\n",
    "    #X = X.join(cluster_distance(X, cluster_features))\n",
    "\n",
    "    #Label Encoding\n",
    "    X = label_encode(X)\n",
    "\n",
    "    #print(len(X))\n",
    "    #Reform Splits\n",
    "    #print(df_test.index.isin(X.index).sum())\n",
    "    if df_test is not None:\n",
    "        X.reset_index(drop=True, inplace=True) #It is very very important step otherwise loc may not work\n",
    "        df_test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        X_test = X.loc[df_test.index, :]\n",
    "        X.drop(df_test.index, inplace=True)\n",
    "\n",
    "    #print(len(X))\n",
    "    #print(len(X_test))\n",
    "    \"\"\"\n",
    "    #Removing duplicate indexes by resetting\n",
    "    X = X.reset_index(drop=True) #It is very very important step\n",
    "    y = y.reset_index(drop=True)\n",
    "\n",
    "    #Aligning training and target dataframe for mismatched indexes or NaNs\n",
    "    X, y = X.align(y, join='inner', axis=0) #It is very very important step so that no. of rows remain\n",
    "                                            #same in X and y\n",
    "    #Target Encoding\n",
    "    encoder = CrossFoldEncoder(MEstimateEncoder, m=1)\n",
    "    X = X.join(encoder.fit_transform(X, y, cols = [\"MSSubClass\"]))\n",
    "    X = X.join(encoder.fit_transform(X, y, cols = [\"Neighborhood\"]))\n",
    "    if df_test is not None:\n",
    "        X_test = X_test.join(encoder.transform(X_test))\n",
    "    \"\"\"\n",
    "    if df_test is not None:\n",
    "        return X, y, X_test\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc123af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:27:57.539741Z",
     "iopub.status.busy": "2025-02-10T17:27:57.539377Z",
     "iopub.status.idle": "2025-02-10T17:28:00.825945Z",
     "shell.execute_reply": "2025-02-10T17:28:00.824511Z"
    },
    "papermill": {
     "duration": 3.295395,
     "end_time": "2025-02-10T17:28:00.827827",
     "exception": false,
     "start_time": "2025-02-10T17:27:57.532432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17453565383024972"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test = create_features(df_train, df_test)\n",
    "\n",
    "score_dataset(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9288c7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:28:00.842587Z",
     "iopub.status.busy": "2025-02-10T17:28:00.842195Z",
     "iopub.status.idle": "2025-02-10T17:28:00.848248Z",
     "shell.execute_reply": "2025-02-10T17:28:00.847206Z"
    },
    "papermill": {
     "duration": 0.014971,
     "end_time": "2025-02-10T17:28:00.849842",
     "exception": false,
     "start_time": "2025-02-10T17:28:00.834871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#Optuna Visualization for hyperparamter tuning\\nimport optuna\\n\\ndef objective(trial):\\n    xgb_params = dict(\\n        max_depth = trial.suggest_int(\"max_depth\", 2, 10),\\n        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\\n        n_estimators = trial.suggest_int(\"n_estimators\", 1000, 8000),\\n        min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10),\\n        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\\n        subsample = trial.suggest_float(\"subsample\", 0.2, 1.0),\\n        reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\\n        reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True)\\n    )\\n    xgb = XGBRegressor(**xgb_params)\\n    return score_dataset(X_train, y_train, xgb)\\n\\nstudy = optuna.create_study(direction = \"minimize\")\\nstudy.optimize(objective, n_trials = 20)\\nxgb_params = study.best_params\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "#Optuna Visualization for hyperparamter tuning\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        max_depth = trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-1, log=True),\n",
    "        n_estimators = trial.suggest_int(\"n_estimators\", 1000, 8000),\n",
    "        min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample = trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha = trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda = trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True)\n",
    "    )\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    return score_dataset(X_train, y_train, xgb)\n",
    "\n",
    "study = optuna.create_study(direction = \"minimize\")\n",
    "study.optimize(objective, n_trials = 20)\n",
    "xgb_params = study.best_params\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffaa368f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:28:00.863929Z",
     "iopub.status.busy": "2025-02-10T17:28:00.863532Z",
     "iopub.status.idle": "2025-02-10T17:28:00.868639Z",
     "shell.execute_reply": "2025-02-10T17:28:00.867496Z"
    },
    "papermill": {
     "duration": 0.014101,
     "end_time": "2025-02-10T17:28:00.870415",
     "exception": false,
     "start_time": "2025-02-10T17:28:00.856314",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#since trial_9 has minimum error as obtained from optuna visualization\n",
    "xgb_params = dict(\n",
    "    max_depth = 8,\n",
    "    learning_rate = 0.0012352725932045963,\n",
    "    n_estimators = 7121,\n",
    "    min_child_weight = 2,\n",
    "    colsample_bytree = 0.49085760982707777,\n",
    "    subsample = 0.44421169619647927,\n",
    "    reg_alpha = 0.00021184484530038537,\n",
    "    reg_lambda = 0.07172122643270866,\n",
    "    num_parallel_tree = 1\n",
    ")\n",
    "xgb = XGBRegressor(**xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91fbbe69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T17:28:00.884847Z",
     "iopub.status.busy": "2025-02-10T17:28:00.884450Z",
     "iopub.status.idle": "2025-02-10T17:28:30.308903Z",
     "shell.execute_reply": "2025-02-10T17:28:30.307727Z"
    },
    "papermill": {
     "duration": 29.433776,
     "end_time": "2025-02-10T17:28:30.310857",
     "exception": false,
     "start_time": "2025-02-10T17:28:00.877081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved successfully_RR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1461</td>\n",
       "      <td>127792.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1462</td>\n",
       "      <td>158114.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1463</td>\n",
       "      <td>189654.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1464</td>\n",
       "      <td>188545.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1465</td>\n",
       "      <td>185565.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  SalePrice\n",
       "0  1461  127792.78\n",
       "1  1462  158114.86\n",
       "2  1463  189654.42\n",
       "3  1464  188545.52\n",
       "4  1465  185565.92"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train, np.log(y_train))\n",
    "predictions = np.exp(xgb.predict(X_test))\n",
    "\n",
    "id_list = []\n",
    "for i in range(1461, 2920):\n",
    "    id_list.append(i)\n",
    "output = pd.DataFrame({\"Id\":id_list, \"SalePrice\":predictions})\n",
    "output.to_csv(\"my_submission.csv\", index = False)\n",
    "print(\"Submission saved successfully_RR\")\n",
    "see = pd.read_csv(\"my_submission.csv\")\n",
    "see.head()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 868283,
     "sourceId": 5407,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 41.684324,
   "end_time": "2025-02-10T17:28:31.138901",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-10T17:27:49.454577",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
